{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load the dataset\n",
    "data_frame = read_csv(\"IRIS.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(151, 5)\n"
     ]
    }
   ],
   "source": [
    "print(data_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the duplicates present\n",
    "duplicates = data_frame.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "       0    1    2    3               4\n",
      "35   4.9  3.1  1.5  0.1     Iris-setosa\n",
      "38   4.9  3.1  1.5  0.1     Iris-setosa\n",
      "143  5.8  2.7  5.1  1.9  Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "# output the duplicates if there are any duplicates\n",
    "print(duplicates.any())\n",
    "# list all duplicate rows\n",
    "print(data_frame[duplicates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(148, 5)\n"
     ]
    }
   ],
   "source": [
    "data_frame.drop_duplicates(inplace=True)\n",
    "print(data_frame.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute the missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.         2.        ]\n",
      " [6.         6.33333333]\n",
      " [7.         6.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "impute = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "impute.fit([[2, 5], [np.nan, 8], [4, 6]])\n",
    "SimpleImputer()\n",
    "X = [[np.nan, 2], [6, np.nan], [7, 6]]\n",
    "print(impute.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In case of sparse metrices too, SimpleImputer works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.66666667 2.        ]\n",
      " [6.         1.33333333]\n",
      " [7.         6.        ]]\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "matrix = sp.csc_matrix([[2, 4], [0, -2], [6, 2]])\n",
    "impute = SimpleImputer(missing_values=-1, strategy='mean')\n",
    "impute.fit(matrix)\n",
    "SimpleImputer(missing_values=-1)\n",
    "matrix_test = sp.csc_matrix([[-1, 2], [6, -1], [7, 6]])\n",
    "print(impute.transform(matrix_test).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['New York' 'New Delhi']\n",
      " ['New York' 'Tokyo']\n",
      " ['New York' 'Tokyo']\n",
      " ['New York' 'Tokyo']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data_frame = pd.DataFrame([[\"New York\", \"New Delhi\"],[np.nan, \"Tokyo\"],[\"New York\", np.nan],[\"New York\", \"Tokyo\"]], dtype=\"category\")\n",
    "\n",
    "impute = SimpleImputer(strategy=\"most_frequent\")\n",
    "print(impute.fit_transform(data_frame))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute missing values using machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_dictionary = {'Variable_A': [200, 190, 90, 149, np.nan],\n",
    "                     'Variable_B': [400, np.nan, 149, 200, 205],\n",
    "                     'Variable_C': [200,149, np.nan, 155, 165],\n",
    "                     'Variable_D': [200, np.nan, 90, 149,100],\n",
    "                     'Variable_E': [200, 190, 90, 149, np.nan],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_df = pd.DataFrame(missing_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable_A</th>\n",
       "      <th>Variable_B</th>\n",
       "      <th>Variable_C</th>\n",
       "      <th>Variable_D</th>\n",
       "      <th>Variable_E</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>400.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>190.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>149.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>90.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>149.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>149.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable_A  Variable_B  Variable_C  Variable_D  Variable_E\n",
       "0       200.0       400.0       200.0       200.0       200.0\n",
       "1       190.0         NaN       149.0         NaN       190.0\n",
       "2        90.0       149.0         NaN        90.0        90.0\n",
       "3       149.0       200.0       155.0       149.0       149.0\n",
       "4         NaN       205.0       165.0       100.0         NaN"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_imputer = KNNImputer(n_neighbors=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_df = missing_imputer.fit_transform(missing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[200. , 400. , 200. , 200. , 200. ],\n",
       "       [190. , 302.5, 149. , 150. , 190. ],\n",
       "       [ 90. , 149. , 160. ,  90. ,  90. ],\n",
       "       [149. , 200. , 155. , 149. , 149. ],\n",
       "       [169.5, 205. , 165. , 100. , 169.5]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Imbalance using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from imblearn.combine import  SMOTETomek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data and create X, y\n",
    "credit_card_data_set = pd.read_csv('creditcard.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = credit_card_data_set.iloc[:,:-1]\n",
    "y = credit_card_data_set.iloc[:,-1].map({1:'Fraud', 0:'No Fraud'})\n",
    "\n",
    "# Resample data\n",
    "X_resampled, y_resampled = SMOTE(sampling_strategy={\"Fraud\":500}).fit_resample(X, y)\n",
    "X_resampled = pd.DataFrame(X_resampled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0_original = len(credit_card_data_set[credit_card_data_set.Class==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1_original = len(credit_card_data_set[credit_card_data_set.Class==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.001727485630620034\n"
     ]
    }
   ],
   "source": [
    "print(class_1_original/(class_0_original+class_1_original))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_0 = len(y_sampled[y_sampled==0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_1 = len(y_sampled[y_sampled==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(sampled_1/(sampled_0+sampled_1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
